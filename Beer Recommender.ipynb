{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X8auUeRDfUhI"
      },
      "source": [
        "## Beer Recommendation System\n",
        "\n",
        "1. **Task A** -> Scraping\n",
        "2. **Task B** -> Bag-of-Words (TF-IDF + Sentiment)  \n",
        "3. **Task C** -> Word2Vec Embeddings  \n",
        "4. **Task D** -> SpaCy Embeddings  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-1fnu6L_zRv",
        "outputId": "e57dec85-a249-472d-d779-da3872a4aea8",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: beautifulsoup4 in /opt/anaconda3/lib/python3.13/site-packages (4.12.3)\n",
            "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.13/site-packages (2.32.3)\n",
            "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.13/site-packages (2.2.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /opt/anaconda3/lib/python3.13/site-packages (from beautifulsoup4) (2.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.13/site-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.13/site-packages (from requests) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.13/site-packages (from requests) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.13/site-packages (from requests) (2025.8.3)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /opt/anaconda3/lib/python3.13/site-packages (from pandas) (2.1.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.13/site-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.13/site-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.13/site-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Resuming: 230 beers scraped, 10000 reviews.\n",
            "Found 250 beers\n",
            "Skipping Kentucky Brunch Brand Stout, already scraped.\n",
            "Skipping Marshmallow Handjee, already scraped.\n",
            "Skipping Abraxas - Barrel-Aged, already scraped.\n",
            "Skipping R&D Sour Fruit (Very Sour Blackberry), already scraped.\n",
            "Skipping Hunahpu's Imperial Stout - Double Barrel Aged, already scraped.\n",
            "Skipping Heady Topper, already scraped.\n",
            "Skipping Mornin' Delight, already scraped.\n",
            "Skipping King Julius, already scraped.\n",
            "Skipping Pliny The Younger, already scraped.\n",
            "Skipping King JJJuliusss, already scraped.\n",
            "Skipping O.W.K., already scraped.\n",
            "Skipping Blessed, already scraped.\n",
            "Skipping M.J.K., already scraped.\n",
            "Skipping Black Magick - Pappy Van Winkle, already scraped.\n",
            "Skipping Fundamental Observation, already scraped.\n",
            "Skipping Very Hazy, already scraped.\n",
            "Skipping Zenne Y Frontera, already scraped.\n",
            "Skipping Bourbon County Brand Vanilla Rye Stout, already scraped.\n",
            "Skipping A Deal With The Devil - Triple Oak-Aged, already scraped.\n",
            "Skipping Barrel Aged Imperial German Chocolate Cupcake Stout, already scraped.\n",
            "Skipping Fou' Foune, already scraped.\n",
            "Skipping Very Green, already scraped.\n",
            "Skipping Assassin, already scraped.\n",
            "Skipping Juice Machine, already scraped.\n",
            "Skipping Pliny The Elder, already scraped.\n",
            "Skipping V.S.O.J., already scraped.\n",
            "Skipping CBS (Canadian Breakfast Stout), already scraped.\n",
            "Skipping Julius, already scraped.\n",
            "Skipping A Deal With The Devil - Double Oak-Aged, already scraped.\n",
            "Skipping Double Barrel V.S.O.J., already scraped.\n",
            "Skipping Abner, already scraped.\n",
            "Skipping Double Sunshine, already scraped.\n",
            "Skipping Coconut Vibes - Barrel-Aged, already scraped.\n",
            "Skipping Very GGGreennn, already scraped.\n",
            "Skipping Clover, already scraped.\n",
            "Skipping Chemtrailmix - Rye Barrel, already scraped.\n",
            "Skipping Westly, already scraped.\n",
            "Skipping Jjjuliusss, already scraped.\n",
            "Skipping Dinner, already scraped.\n",
            "Skipping Anabasis, already scraped.\n",
            "Skipping Duck Duck Gooze, already scraped.\n",
            "Skipping Lou Pepe - Kriek, already scraped.\n",
            "Skipping Morning Wood, already scraped.\n",
            "Skipping Trappist Westvleteren 12 (XII), already scraped.\n",
            "Skipping Speedway Stout - Vietnamese Coffee - Bourbon Barrel-Aged, already scraped.\n",
            "Skipping 10 Year Barleywine, already scraped.\n",
            "Skipping Framboise Du Fermier, already scraped.\n",
            "Skipping KBS, already scraped.\n",
            "Skipping Bourbon County Brand Stout, already scraped.\n",
            "Skipping Oude Fermier, already scraped.\n",
            "Skipping Doubleganger, already scraped.\n",
            "Skipping Parabola, already scraped.\n",
            "Skipping Fuzzy, already scraped.\n",
            "Skipping Snowed In - Bourbon Barrel-Aged, already scraped.\n",
            "Skipping Monster Tones, already scraped.\n",
            "Skipping Double Citra®, already scraped.\n",
            "Skipping Ann, already scraped.\n",
            "Skipping Aaron, already scraped.\n",
            "Skipping Samuel, already scraped.\n",
            "Skipping Atrial Rubicite, already scraped.\n",
            "Skipping Maman, already scraped.\n",
            "Skipping Double Galaxy, already scraped.\n",
            "Skipping Double Dry Hopped Congress Street, already scraped.\n",
            "Skipping Nectarine Premiere, already scraped.\n",
            "Skipping Headroom, already scraped.\n",
            "Skipping Society & Solitude #4, already scraped.\n",
            "Skipping Lou Pepe - Framboise, already scraped.\n",
            "Skipping Zombie Dust, already scraped.\n",
            "Skipping Cable Car, already scraped.\n",
            "Skipping Very HHHazyyy, already scraped.\n",
            "Skipping Hunahpu's Imperial Stout, already scraped.\n",
            "Skipping King Sue, already scraped.\n",
            "Skipping Green, already scraped.\n",
            "Skipping Haze, already scraped.\n",
            "Skipping Flora Plum, already scraped.\n",
            "Skipping Oude Geuze Vintage, already scraped.\n",
            "Skipping Doppelganger, already scraped.\n",
            "Skipping Fort Point Pale Ale - Double Dry Hopped, already scraped.\n",
            "Skipping Swish, already scraped.\n",
            "Skipping Ghost In The Machine - Double Dry-Hopped, already scraped.\n",
            "Skipping Brandy Barrel Aged Dark Lord With Vanilla Beans, already scraped.\n",
            "Skipping Grande Negro Voodoo Papi - Bourbon Barrel-Aged, already scraped.\n",
            "Skipping Focal Banger, already scraped.\n",
            "Skipping The Adjunct Trail - Bourbon Barrel-Aged, already scraped.\n",
            "Skipping Abricot Du Fermier, already scraped.\n",
            "Skipping Coconut Vibes, already scraped.\n",
            "Skipping Triple Shot, already scraped.\n",
            "Skipping West Ashley, already scraped.\n",
            "Skipping Coffee Cinnamon B-Bomb, already scraped.\n",
            "Skipping The Broken Truck, already scraped.\n",
            "Skipping Supplication, already scraped.\n",
            "Skipping Sip Of Sunshine, already scraped.\n",
            "Skipping Saison Du Fermier, already scraped.\n",
            "Skipping Bourbon Paradise, already scraped.\n",
            "Skipping The Rusty Nail, already scraped.\n",
            "Skipping Fourth Dementia - Bourbon Barrel-Aged, already scraped.\n",
            "Skipping Citra, already scraped.\n",
            "Skipping Fort Point Pale Ale -  Galaxy Dry Hopped, already scraped.\n",
            "Skipping Triple Sunshine, already scraped.\n",
            "Skipping Ephraim, already scraped.\n",
            "Skipping Black Note Stout, already scraped.\n",
            "Skipping Black Tuesday, already scraped.\n",
            "Skipping Beatification, already scraped.\n",
            "Skipping Alter Ego, already scraped.\n",
            "Skipping Sunday Brunch, already scraped.\n",
            "Skipping Saint Lamvinus, already scraped.\n",
            "Skipping Society & Solitude #5, already scraped.\n",
            "Skipping Mexican Brunch, already scraped.\n",
            "Skipping Last Buffalo In The Park, already scraped.\n",
            "Skipping Chocolate Rain, already scraped.\n",
            "Skipping Black Gold, already scraped.\n",
            "Skipping Miami Madness, already scraped.\n",
            "Skipping 4th Anniversary, already scraped.\n",
            "Skipping Beyond Good And Evil, already scraped.\n",
            "Skipping The Peach, already scraped.\n",
            "Skipping Double Shot, already scraped.\n",
            "Skipping Gggreennn!, already scraped.\n",
            "Skipping Parabajava, already scraped.\n",
            "Skipping Plead The 5th - Bourbon Barrel-Aged, already scraped.\n",
            "Skipping Notorious Triple IPA, already scraped.\n",
            "Skipping Medianoche - Coconut, already scraped.\n",
            "Skipping Leaner, already scraped.\n",
            "Skipping Cutting Tiles - Mosaic, already scraped.\n",
            "Skipping Pseudo Sue - Double Dry-Hopped, already scraped.\n",
            "Skipping I Let My Tape Rock, already scraped.\n",
            "Skipping Breakfast Stout, already scraped.\n",
            "Skipping In Perpetuity, already scraped.\n",
            "Skipping Moment Of Clarity, already scraped.\n",
            "Skipping Fundamental Forces, already scraped.\n",
            "Skipping §ucaba, already scraped.\n",
            "Skipping Wide Awake It's Morning, already scraped.\n",
            "Skipping Kaggen! Stormaktsporter, already scraped.\n",
            "Skipping Double Nelson, already scraped.\n",
            "Skipping Framboos, already scraped.\n",
            "Skipping Blåbær Lambik, already scraped.\n",
            "Skipping Pirate Bomb!, already scraped.\n",
            "Skipping Speedway Stout - Bourbon Barrel-Aged, already scraped.\n",
            "Skipping Emperor Julius, already scraped.\n",
            "Skipping King Sue - Double Dry-Hopped, already scraped.\n",
            "Skipping Double Dry Hopped Double Mosaic Dream, already scraped.\n",
            "Skipping Grey Monday, already scraped.\n",
            "Skipping Barrel-Aged Sump Coffee Stout, already scraped.\n",
            "Skipping Nillerzzzzz, already scraped.\n",
            "Skipping Truth, already scraped.\n",
            "Skipping JJJuiceee Machine, already scraped.\n",
            "Skipping Lou Pepe - Gueuze, already scraped.\n",
            "Skipping Trappistes Rochefort 10, already scraped.\n",
            "Skipping Society & Solitude #6, already scraped.\n",
            "Skipping Art, already scraped.\n",
            "Skipping Montmorency Vs Balaton, already scraped.\n",
            "Skipping BVC, already scraped.\n",
            "Skipping Susan, already scraped.\n",
            "Skipping Speedway Stout - Vietnamese Coffee, already scraped.\n",
            "Skipping Double Dry Hopped Mylar Bags, already scraped.\n",
            "Skipping Modem Tones - Bourbon Barrel-Aged - Vanilla, already scraped.\n",
            "Skipping Double Dry Hopped Melcher Street, already scraped.\n",
            "Skipping Fort Point Pale Ale - Mosaic Dry Hopped, already scraped.\n",
            "Skipping Heavy Mettle, already scraped.\n",
            "Skipping Oude Geuze Golden Blend, already scraped.\n",
            "Skipping Hommage, already scraped.\n",
            "Skipping Saison Bernice, already scraped.\n",
            "Skipping Upper Case, already scraped.\n",
            "Skipping Bomb!, already scraped.\n",
            "Skipping Dorothy (Wine Barrel Aged), already scraped.\n",
            "Skipping Pseudo Sue, already scraped.\n",
            "Skipping Consecration, already scraped.\n",
            "Skipping Abrasive Ale, already scraped.\n",
            "Skipping Canuckley, already scraped.\n",
            "Skipping Double Dry Hopped Double Mosaic Daydream, already scraped.\n",
            "Skipping Rocky Road - Bourbon Barrel-Aged, already scraped.\n",
            "Skipping Permanent Funeral, already scraped.\n",
            "Skipping Everett, already scraped.\n",
            "Skipping Congress Street IPA, already scraped.\n",
            "Skipping The Greenest Green, already scraped.\n",
            "Skipping Somewhere, Something Incredible Is Waiting To Be Known, already scraped.\n",
            "Skipping La Fosse, already scraped.\n",
            "Skipping Mocha Wednesday, already scraped.\n",
            "Skipping Adios Ghost, already scraped.\n",
            "Skipping Speedway Stout - Vietnamese Coffee - Rye Whiskey Barrel-Aged, already scraped.\n",
            "Skipping Cutting Tiles - Galaxy, already scraped.\n",
            "Skipping BDCS, already scraped.\n",
            "Skipping Impermanence, already scraped.\n",
            "Skipping Barrel-Aged Silhouette, already scraped.\n",
            "Skipping B-Bomb - Coconut, already scraped.\n",
            "Skipping KBS - Maple Mackinac Fudge, already scraped.\n",
            "Skipping Darkness, already scraped.\n",
            "Skipping Damon, already scraped.\n",
            "Skipping DFPF, already scraped.\n",
            "Skipping Foggier Window, already scraped.\n",
            "Skipping Crusher, already scraped.\n",
            "Skipping Oude Geuze Cuvée Armand & Gaston, already scraped.\n",
            "Skipping Double Stack, already scraped.\n",
            "Skipping Double Dry Hopped All Citra Everything, already scraped.\n",
            "Skipping Hunahpu's Imperial Stout - Bourbon Barrel-Aged, already scraped.\n",
            "Skipping Apple Brandy Barrel Noir, already scraped.\n",
            "Skipping Affogato, already scraped.\n",
            "Skipping Space Trace, already scraped.\n",
            "Skipping No Rules, already scraped.\n",
            "Skipping Hold On To Sunshine, already scraped.\n",
            "Skipping Sunday Brunch - Bourbon Barrel-Aged, already scraped.\n",
            "Skipping Barrel Aged Bomb!, already scraped.\n",
            "Skipping Imperial German Chocolate Cupcake Stout, already scraped.\n",
            "Skipping Abt 12, already scraped.\n",
            "Skipping Affogato - Bourbon Barrel-Aged, already scraped.\n",
            "Skipping The Abyss, already scraped.\n",
            "Skipping Leche Borracho, already scraped.\n",
            "Skipping Abraxas, already scraped.\n",
            "Skipping Stickee Monkee, already scraped.\n",
            "Skipping Samuel Adams Utopias, already scraped.\n",
            "Skipping Aurelian Lure, already scraped.\n",
            "Skipping Midnight Still, already scraped.\n",
            "Skipping Juicy, already scraped.\n",
            "Skipping Darkstar November, already scraped.\n",
            "Skipping Trappist Westvleteren 8 (VIII), already scraped.\n",
            "Skipping Ten FIDY - Bourbon Barrel-Aged, already scraped.\n",
            "Skipping V.S.O.R. Select, already scraped.\n",
            "Skipping Sosus, already scraped.\n",
            "Skipping Smooth, already scraped.\n",
            "Skipping Thicket, already scraped.\n",
            "Skipping Bourbon Barrel Oro Negro, already scraped.\n",
            "Skipping Triple Citra Daydream, already scraped.\n",
            "Skipping Label Us Notorious, already scraped.\n",
            "Skipping CitraQuench'l, already scraped.\n",
            "Skipping Cellarman Barrel Aged Saison, already scraped.\n",
            "Skipping Reaction State, already scraped.\n",
            "Skipping Pliny For President, already scraped.\n",
            "Skipping Schaarbeekse Kriek, already scraped.\n",
            "Skipping All That Is And All That Ever Will Be, already scraped.\n",
            "Skipping Flora, already scraped.\n",
            "Skipping Expedition Stout - Bourbon Barrel-Aged, already scraped.\n",
            "\n",
            "Scraping beer 231/250: Foggy Window\n",
            "Sleeping 104.3s\n",
            "\n",
            "Scraping beer 232/250: Peche Du Fermier\n",
            "Sleeping 136.0s\n",
            "\n",
            "Scraping beer 233/250: Abraxas - Coffee\n",
            "Sleeping 166.6s\n",
            "\n",
            "Scraping beer 234/250: Jam The Radar\n",
            "Sleeping 165.0s\n",
            "\n",
            "Scraping beer 235/250: Maple Bacon Coffee Porter\n",
            "Sleeping 61.3s\n",
            "\n",
            "Scraping beer 236/250: Last Snow\n",
            "Sleeping 89.3s\n",
            "\n",
            "Scraping beer 237/250: Imperial Eclipse Stout - Elijah Craig (12 Year)\n",
            "Sleeping 87.9s\n",
            "\n",
            "Scraping beer 238/250: Bourbon Barrel Champion Ground\n",
            "Sleeping 98.7s\n",
            "\n",
            "Scraping beer 239/250: Bodhi\n",
            "Sleeping 169.2s\n",
            "Skipping Leaner, already scraped.\n",
            "\n",
            "Scraping beer 241/250: Rodenbach Caractère Rouge\n",
            "Sleeping 175.9s\n",
            "\n",
            "Scraping beer 242/250: Double Dry Hopped Double Citra Daydream\n",
            "Sleeping 140.8s\n",
            "\n",
            "Scraping beer 243/250: Birth Of Tragedy\n",
            "Sleeping 71.1s\n",
            "\n",
            "Scraping beer 244/250: Caffè Americano\n",
            "Sleeping 77.9s\n",
            "\n",
            "Scraping beer 245/250: Truth - Vanilla Bean\n",
            "Sleeping 115.9s\n",
            "\n",
            "Scraping beer 246/250: Dragonsaddle\n",
            "Sleeping 102.4s\n",
            "\n",
            "Scraping beer 247/250: Red Eye November\n",
            "Sleeping 173.1s\n",
            "\n",
            "Scraping beer 248/250: Hopslam Ale\n",
            "Sleeping 128.7s\n",
            "\n",
            "Scraping beer 249/250: The Streets\n",
            "Sleeping 146.3s\n",
            "\n",
            "Scraping beer 250/250: Emerald Grouper\n",
            "Sleeping 165.5s\n",
            "\n",
            "Total reviews collected: 10000\n"
          ]
        }
      ],
      "source": [
        "# # ===============================\n",
        "# # Install Packages\n",
        "# # ===============================\n",
        "# !pip install beautifulsoup4 requests pandas\n",
        "\n",
        "# # ===============================\n",
        "# # Scraper\n",
        "# # ===============================\n",
        "\n",
        "# import time\n",
        "# import random\n",
        "# import pandas as pd\n",
        "# import requests\n",
        "# from bs4 import BeautifulSoup\n",
        "# import os\n",
        "# import tempfile\n",
        "# import shutil\n",
        "\n",
        "# # -----------------------------\n",
        "# # Step 1: Get top beers\n",
        "# # -----------------------------\n",
        "# def get_top_beer_urls():\n",
        "#     url = 'https://www.beeradvocate.com/beer/top-rated/'\n",
        "#     headers = {'User-Agent': 'Mozilla/5.0'}\n",
        "#     try:\n",
        "#         resp = requests.get(url, headers=headers, timeout=10)\n",
        "#         resp.raise_for_status()\n",
        "#     except Exception as e:\n",
        "#         print(f\"Failed to fetch top beers: {e}\")\n",
        "#         return []\n",
        "\n",
        "#     soup = BeautifulSoup(resp.text, 'html.parser')\n",
        "#     beer_data = []\n",
        "\n",
        "#     for row in soup.select('tr'):\n",
        "#         a_tag = row.find('a', href=lambda h: h and \"/beer/profile/\" in h)\n",
        "#         if a_tag:\n",
        "#             beer_name = a_tag.get_text(strip=True)\n",
        "#             beer_url = 'https://www.beeradvocate.com' + a_tag['href']\n",
        "#             beer_data.append({'name': beer_name, 'url': beer_url})\n",
        "\n",
        "#     print(f\"Found {len(beer_data)} beers\")\n",
        "#     return beer_data\n",
        "\n",
        "# # -----------------------------\n",
        "# # Human-like behavior (simplified for requests)\n",
        "# # -----------------------------\n",
        "# def human_delay(base_range=(2, 5)):\n",
        "#     delay = random.uniform(*base_range)\n",
        "#     print(f\"Sleeping {delay:.1f}s\")\n",
        "#     time.sleep(delay)\n",
        "\n",
        "# # -----------------------------\n",
        "# # Scrape reviews using requests and BeautifulSoup\n",
        "# # -----------------------------\n",
        "# def scrape_all_reviews(beer_name, beer_url, max_reviews=40):\n",
        "#     all_reviews = []\n",
        "#     reviews_count = 0\n",
        "#     current_url = beer_url\n",
        "#     # Added more headers to mimic a browser\n",
        "#     headers = {\n",
        "#         'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\n",
        "#         'Accept-Language': 'en-US,en;q=0.9',\n",
        "#         'Referer': 'https://www.beeradvocate.com/beer/top-rated/', # Refer from the top-rated page\n",
        "#         'DNT': '1', # Do Not Track Request Header\n",
        "#         'Upgrade-Insecure-Requests': '1',\n",
        "#     }\n",
        "\n",
        "\n",
        "#     while True:\n",
        "#         if reviews_count >= max_reviews:\n",
        "#             print(f\"Reached {max_reviews} reviews for {beer_name}.\")\n",
        "#             break\n",
        "\n",
        "#         try:\n",
        "#             resp = requests.get(current_url, headers=headers, timeout=15) # Increased timeout for review pages\n",
        "#             resp.raise_for_status()\n",
        "#         except Exception as e:\n",
        "#             # print(f\"Failed to fetch review page for {beer_name} ({current_url}): {e}\")\n",
        "#             break\n",
        "\n",
        "#         soup = BeautifulSoup(resp.text, 'html.parser')\n",
        "#         review_divs = soup.select('div[id^=\"rating_fullview_content_\"]')\n",
        "\n",
        "#         if not review_divs:\n",
        "#             print(f\"No more reviews found on this page for {beer_name}.\")\n",
        "#             break\n",
        "\n",
        "#         for div in review_divs:\n",
        "#             if reviews_count >= max_reviews:\n",
        "#                 break\n",
        "#             try:\n",
        "#                 rating_el = div.select_one('.BAscore_norm')\n",
        "#                 rating = rating_el.get_text(strip=True) if rating_el else \"N/A\"\n",
        "#                 review_text_div = div.select_one('div[style*=\"line-height:1.4\"]')\n",
        "#                 full_text = review_text_div.decode_contents() if review_text_div else \"\" # Use decode_contents() to get inner HTML\n",
        "#                 clean_review = (\n",
        "#                     full_text.split('<br/><br/>Review date:')[0] # Adjusted split for BeautifulSoup output\n",
        "#                              .split('<br/><br/>Bottle date:')[0] # Adjusted split for BeautifulSoup output\n",
        "#                              .replace('<br/>', '\\n') # Adjusted replace for BeautifulSoup output\n",
        "#                              .strip()\n",
        "#                 )\n",
        "#                 if clean_review:\n",
        "#                     all_reviews.append({'review': clean_review, 'rating': rating})\n",
        "#                     reviews_count += 1\n",
        "#             except Exception as e:\n",
        "#                 print(f\"Error extracting review for {beer_name}: {e}\")\n",
        "#                 continue\n",
        "\n",
        "#         print(f\"Scraped {len(review_divs)} reviews from this page, total so far: {reviews_count}\")\n",
        "\n",
        "#         # Find the next page link\n",
        "#         next_link = soup.select_one('a.next')\n",
        "#         if next_link and 'href' in next_link.attrs:\n",
        "#             current_url = 'https://www.beeradvocate.com' + next_link['href']\n",
        "#             human_delay((3, 7)) # Add delay between pages\n",
        "#         else:\n",
        "#             print(f\"No more pages for {beer_name}.\")\n",
        "#             break\n",
        "\n",
        "#     return all_reviews\n",
        "\n",
        "# # ---------- Main workflow ----------\n",
        "# def main():\n",
        "#     csv_path = 'beer_reviews.csv'\n",
        "#     MAX_TOTAL_REVIEWS = 15000\n",
        "\n",
        "#     all_reviews_data = []\n",
        "#     scraped_beers = set()\n",
        "\n",
        "#     if os.path.exists(csv_path):\n",
        "#         try:\n",
        "#             df_existing = pd.read_csv(csv_path)\n",
        "#             all_reviews_data = df_existing.to_dict(\"records\")\n",
        "#             scraped_beers = set(df_existing[\"product_name\"].unique())\n",
        "#             print(f\"Resuming: {len(scraped_beers)} beers scraped, {len(all_reviews_data)} reviews.\")\n",
        "#         except pd.errors.EmptyDataError:\n",
        "#             print(f\"{csv_path} exists but is empty. Starting fresh.\")\n",
        "#             all_reviews_data = []\n",
        "#             scraped_beers = set()\n",
        "#         except Exception as e:\n",
        "#             print(f\"Error reading existing CSV file: {e}. Starting fresh.\")\n",
        "#             all_reviews_data = []\n",
        "#             scraped_beers = set()\n",
        "\n",
        "#     if not os.path.exists(csv_path) or os.path.getsize(csv_path) == 0:\n",
        "#          # Ensure header is written if starting fresh or file was empty\n",
        "#         pd.DataFrame(columns=['review', 'rating', 'product_name']).to_csv(csv_path, index=False)\n",
        "\n",
        "\n",
        "#     beer_list = get_top_beer_urls()\n",
        "\n",
        "#     for i, beer in enumerate(beer_list):\n",
        "#         if len(all_reviews_data) >= MAX_TOTAL_REVIEWS:\n",
        "#             print(f\"Reached {MAX_TOTAL_REVIEWS} total reviews. Stopping.\")\n",
        "#             break\n",
        "\n",
        "#         beer_name = beer['name']\n",
        "#         beer_url = beer['url']\n",
        "\n",
        "#         if beer_name in scraped_beers:\n",
        "#             print(f\"Skipping {beer_name}, already scraped.\")\n",
        "#             continue\n",
        "\n",
        "#         print(f\"\\nScraping beer {i+1}/{len(beer_list)}: {beer_name}\")\n",
        "#         # Call the refactored scraping function\n",
        "#         revs = scrape_all_reviews(beer_name, beer_url, max_reviews=40)\n",
        "\n",
        "#         for r in revs:\n",
        "#             r['product_name'] = beer_name\n",
        "#         all_reviews_data.extend(revs)\n",
        "\n",
        "#         pd.DataFrame(all_reviews_data).to_csv(csv_path, index=False)\n",
        "#         # print(f\"Progress saved. Total reviews: {len(all_reviews_data)}\")\n",
        "\n",
        "#         human_delay((60, 180)) # Long break between beers\n",
        "\n",
        "#     print(f\"\\nTotal reviews collected: {len(all_reviews_data)}\")\n",
        "\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "#     main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQXB2WfMbCr3"
      },
      "source": [
        "\n",
        "## Task B - 1st part:\n",
        "To determine the attributes, we first create a word frequency file and then pick the top three based on manual review of top 150-200 words sorted by descending occurences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k5y9zBIbbCr6",
        "outputId": "4259cb7a-52ab-4fb3-8ac2-2e5bf632bbf1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting en-core-web-md==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.8.0/en_core_web_md-3.8.0-py3-none-any.whl (33.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.5/33.5 MB\u001b[0m \u001b[31m47.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: en-core-web-md\n",
            "Successfully installed en-core-web-md-3.8.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_md')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ],
      "source": [
        "!python -m spacy download en_core_web_md"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZYo6kgTlbCr6",
        "outputId": "985eac4d-d5bf-4b3d-b384-e3e26eef075d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.12/dist-packages (4.3.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.26.4)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.3.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart-open>=1.8.1->gensim) (1.17.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install gensim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5mb2-8mMbCr3",
        "outputId": "f01c9628-9959-4bee-c406-647409223b13",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top 20 words:\n",
            "           word  count\n",
            "23         beer   6869\n",
            "15         head   5024\n",
            "165        dark   4124\n",
            "90    chocolate   4046\n",
            "124       sweet   3342\n",
            "77         like   3290\n",
            "51        taste   3261\n",
            "129     vanilla   3064\n",
            "104         one   3017\n",
            "35        notes   2968\n",
            "34       coffee   2896\n",
            "219        nice   2888\n",
            "121     bourbon   2872\n",
            "0          good   2679\n",
            "8         light   2669\n",
            "28         nose   2555\n",
            "52         well   2479\n",
            "2594     orange   2382\n",
            "411       fruit   2319\n",
            "44          bit   2311\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import string\n",
        "from collections import Counter\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "\n",
        "# Download stopwords if not already\n",
        "nltk.download(\"stopwords\")\n",
        "\n",
        "df = pd.read_csv(\"/content/beer_reviews.csv\")\n",
        "\n",
        "# English stopwords\n",
        "stop_words = set(stopwords.words(\"english\"))\n",
        "\n",
        "# Clean and tokenize reviews\n",
        "def preprocess(text):\n",
        "    # Lowercase\n",
        "    text = text.lower()\n",
        "    # Remove punctuation\n",
        "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
        "    # Tokenize\n",
        "    words = re.findall(r\"\\b\\w+\\b\", text)\n",
        "    # Remove stopwords and short tokens\n",
        "    words = [w for w in words if w not in stop_words and len(w) > 2]\n",
        "    return words\n",
        "\n",
        "# Apply preprocessing\n",
        "all_words = []\n",
        "for review in df[\"product_review\"].dropna():\n",
        "    all_words.extend(preprocess(review))\n",
        "\n",
        "# Count frequencies\n",
        "word_freq = Counter(all_words)\n",
        "\n",
        "# Convert to DataFrame\n",
        "freq_df = pd.DataFrame(word_freq.items(), columns=[\"word\", \"count\"]).sort_values(by=\"count\", ascending=False)\n",
        "\n",
        "# Save to CSV\n",
        "freq_df.to_csv(\"word_frequencies.csv\", index=False)\n",
        "\n",
        "print(\"Top 20 words:\")\n",
        "print(freq_df.head(20))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K3amAYuZbCr4"
      },
      "source": [
        "## The top 3 attributes are **Sweet**, **Smooth** and **Hoppy**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vt0tU10rbCr4"
      },
      "source": [
        "##Task B - 2nd Part - Bag-of-Words (TF-IDF + Sentiment):\n",
        "\n",
        "1. We have used a **TF-IDF vectorizer** combined with **cosine similarity** and\n",
        "sentiment scores to recommend beers that best match user preferences.\n",
        "2. The idea is to recommend beers based on how closely their reviews match the user’s preferred attributes (like sweet, smooth, hoppy), while also considering whether the reviews are written in a positive or negative tone\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "vtyd79sxbCr4"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "tINgOTx8bCr4"
      },
      "outputs": [],
      "source": [
        "# ============================================\n",
        "# Step 2: Data Preprocessing (Enhanced)\n",
        "# ============================================\n",
        "\n",
        "import re\n",
        "import pandas as pd\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "\n",
        "# Example stop words\n",
        "STOP_WORDS = set([\"the\", \"and\", \"a\", \"of\", \"to\", \"in\", \"is\", \"it\", \"this\"])\n",
        "\n",
        "# Customer-specified attributes\n",
        "USER_ATTRIBUTES = [\"sweet\", \"smooth\", \"hoppy\"]\n",
        "\n",
        "# Attribute synonyms for BoW/TF-IDF models\n",
        "ATTRIBUTE_SYNONYMS = {\n",
        "    \"sweet\": [\"sweet\", \"sugary\", \"caramel\", \"vanilla\", \"molasses\", \"toffee\",\n",
        "              \"chocolate\", \"bourbon\", \"maple\"],\n",
        "    \"smooth\": [\"smooth\", \"silky\", \"creamy\", \"mellow\", \"rounded\", \"velvet\"],\n",
        "    \"hoppy\": [\"hop\", \"hops\", \"hoppy\", \"bitter\", \"bitterness\", \"citrus\",\n",
        "              \"pine\", \"resin\", \"floral\", \"grapefruit\", \"orange\"]\n",
        "}\n",
        "\n",
        "ATTRIBUTE_RULES = {\n",
        "    \"sweet\": {\n",
        "        \"neg_strong\": [r\"\\bcloying\\b\", r\"\\btoo\\s+sweet\\b\", r\"\\boverly\\s+sweet\\b\",\n",
        "                       r\"\\bsickly\\s+sweet\\b\", r\"\\bexcessively\\s+sweet\\b\"],\n",
        "        \"neg\": [r\"\\bnot\\s+sweet\\b\", r\"\\bartificial(ly)?\\s+sweet\\b\", r\"\\bsyrupy\\b\",\n",
        "                r\"\\blacks?\\s+sweet(ness)?\\b\"],\n",
        "        \"pos\": [r\"\\bpleasantly\\s+sweet\\b\", r\"\\bsubtly\\s+sweet\\b\",\n",
        "                r\"\\bbalanced\\s+sweet(ness)?\\b\"]\n",
        "    },\n",
        "    \"smooth\": {\n",
        "        \"neg_strong\": [r\"\\bnot\\s+smooth\\b\", r\"\\bharsh\\b\", r\"\\bastringent\\b\", r\"\\brough\\b\"],\n",
        "        \"neg\": [r\"\\bthin\\b\", r\"\\bsharp\\b\"],\n",
        "        \"pos\": [r\"\\bsilky\\b\", r\"\\bcreamy\\b\", r\"\\bvelvety\\b\", r\"\\bbuttery\\b\",\n",
        "                r\"\\b(very|super|ultra|really|exceptionally)\\s+smooth\\b\",\n",
        "                r\"\\bsmooth\\s+and\\s+(silky|creamy|velvety|buttery)\\b\"]\n",
        "    },\n",
        "    \"hoppy\": {\n",
        "        \"neg_strong\": [r\"\\boverly\\s+hoppy\\b\", r\"\\btoo\\s+hoppy\\b\", r\"\\bexcessively\\s+hoppy\\b\"],\n",
        "        \"neg\": [r\"\\bnot\\s+hoppy\\b\", r\"\\blacks?\\s+hops?\\b\"],\n",
        "        \"pos\": [r\"\\bnice\\s+hoppy\\b\", r\"\\bpleasantly\\s+hoppy\\b\", r\"\\bhoppy\\s+bite\\b\",\n",
        "                r\"\\bbalanced\\s+hoppy\\b\", r\"\\brefreshingly\\s+hoppy\\b\"]\n",
        "    }\n",
        "}\n",
        "\n",
        "def preprocess_text(text: str) -> list:\n",
        "    if not isinstance(text, str):\n",
        "        return []\n",
        "    text = re.sub(r\"[^a-zA-Z]\", \" \", text).lower()\n",
        "    tokens = word_tokenize(text)\n",
        "    tokens = [t for t in tokens if t not in STOP_WORDS and len(t) > 2]\n",
        "    return tokens\n",
        "\n",
        "def normalize_text(text: str) -> str:\n",
        "    if not isinstance(text, str):\n",
        "        return \"\"\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"[^a-z0-9\\s]\", \" \", text)\n",
        "    return re.sub(r\"\\s+\", \" \", text).strip()\n",
        "\n",
        "def compute_attribute_sentiment(text: str) -> dict:\n",
        "    \"\"\"\n",
        "    Compute attribute-specific sentiment based on ATTRIBUTE_RULES.\n",
        "    Returns a dict: {attribute: score}, where score is in [-1, 1]\n",
        "    \"\"\"\n",
        "    scores = {}\n",
        "    for attr, rules in ATTRIBUTE_RULES.items():\n",
        "        score = 0\n",
        "        for pattern in rules.get(\"neg_strong\", []):\n",
        "            if re.search(pattern, text):\n",
        "                score -= 1.0\n",
        "        for pattern in rules.get(\"neg\", []):\n",
        "            if re.search(pattern, text):\n",
        "                score -= 0.5\n",
        "        for pattern in rules.get(\"pos\", []):\n",
        "            if re.search(pattern, text):\n",
        "                score += 0.5\n",
        "        # Clip score between -1 and 1\n",
        "        scores[attr] = max(min(score, 1.0), -1.0)\n",
        "    return scores\n",
        "\n",
        "def load_and_prepare(path: str) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Load reviews, clean, tokenize, compute VADER sentiment, and attribute-specific sentiment.\n",
        "    \"\"\"\n",
        "    df = pd.read_csv(path)\n",
        "    if \"product_review\" not in df.columns or \"product_name\" not in df.columns:\n",
        "        raise ValueError(\"CSV must contain 'product_name' and 'product_review' columns.\")\n",
        "\n",
        "    # Normalize + tokenize\n",
        "    df[\"clean_review\"] = df[\"product_review\"].apply(normalize_text)\n",
        "    df[\"tokens\"] = df[\"product_review\"].apply(preprocess_text)\n",
        "\n",
        "    # Sentiment (VADER)\n",
        "    sia = SentimentIntensityAnalyzer()\n",
        "    df[\"sentiment_raw\"] = df[\"product_review\"].apply(\n",
        "        lambda x: sia.polarity_scores(str(x))[\"compound\"]\n",
        "    )\n",
        "\n",
        "    # Attribute-specific sentiment\n",
        "    df[\"attribute_sentiment\"] = df[\"product_review\"].apply(compute_attribute_sentiment)\n",
        "\n",
        "    print(f\"✅ Loaded {len(df)} reviews after cleaning and sentiment computation.\")\n",
        "    return df.dropna(subset=[\"clean_review\"]).reset_index(drop=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Idnx70AQbCr5"
      },
      "outputs": [],
      "source": [
        "# ============================================\n",
        "# Step 3: Bag-of-Words Model (Task B)\n",
        "# ============================================\n",
        "\n",
        "def recommend_bow(df: pd.DataFrame, attributes: list, alpha=0.7, top_n=23):\n",
        "    \"\"\"\n",
        "    TF-IDF + Cosine Similarity + Sentiment\n",
        "    \"\"\"\n",
        "    grouped = df.groupby(\"product_name\").agg({\n",
        "        \"clean_review\": \" \".join,\n",
        "        \"sentiment_raw\": \"mean\"\n",
        "    }).reset_index()\n",
        "\n",
        "    # Attribute synonyms for BoW/TF-IDF models\n",
        "    ATTRIBUTE_SYNONYMS = {\n",
        "    \"sweet\": [\"sweet\", \"sugary\", \"caramel\", \"vanilla\", \"molasses\", \"toffee\",\n",
        "              \"chocolate\", \"bourbon\", \"maple\"],\n",
        "    \"smooth\": [\"smooth\", \"silky\", \"creamy\", \"mellow\", \"rounded\", \"velvet\"],\n",
        "    \"hoppy\": [\"hop\", \"hops\", \"hoppy\", \"bitter\", \"bitterness\", \"citrus\",\n",
        "              \"pine\", \"resin\", \"floral\", \"grapefruit\", \"orange\"]\n",
        "    }\n",
        "\n",
        "    # Build query from attributes + synonyms\n",
        "    query_terms = []\n",
        "    for a in attributes:\n",
        "        query_terms.extend(ATTRIBUTE_SYNONYMS.get(a, [a]) * 3)\n",
        "    query_doc = \" \".join(query_terms)\n",
        "\n",
        "    # TF-IDF vectorization\n",
        "    vectorizer = TfidfVectorizer(stop_words=\"english\", max_features=30000)\n",
        "    tfidf_matrix = vectorizer.fit_transform(grouped[\"clean_review\"])\n",
        "    query_vec = vectorizer.transform([query_doc])\n",
        "\n",
        "    # Cosine similarity\n",
        "    cos_sims = cosine_similarity(query_vec, tfidf_matrix).flatten()\n",
        "    cos_norm = MinMaxScaler().fit_transform(cos_sims.reshape(-1, 1)).ravel()\n",
        "\n",
        "    # Sentiment normalization\n",
        "    sent_norm = MinMaxScaler().fit_transform(grouped[[\"sentiment_raw\"]]).ravel()\n",
        "\n",
        "    # Final score\n",
        "    final_score = alpha * cos_norm + (1 - alpha) * sent_norm\n",
        "\n",
        "    recs = grouped.copy()\n",
        "    recs[\"cosine_sim\"] = cos_sims\n",
        "    recs[\"final_score\"] = final_score\n",
        "    return recs.sort_values(\"final_score\", ascending=False).head(top_n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJR5TbhQbCr5"
      },
      "source": [
        "## Task C: Using Pretrained Word Vectors\n",
        "\n",
        "Here we use spaCy’s pretrained word vectors to capture the meaning of words in reviews.\n",
        "\n",
        "1. First, we turn both the reviews and the chosen attributes (with their synonyms) into vector representations.\n",
        "\n",
        "2. Then we measure cosine similarity between reviews and attributes to see how closely they align.\n",
        "\n",
        "3. Finally, we mix in the sentiment score so products that are both relevant and positively reviewed get ranked higher.\n",
        "\n",
        "This gives us a recommendation list that balances semantic closeness with customer sentiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "3cOwFl_fbCr5"
      },
      "outputs": [],
      "source": [
        "import gensim\n",
        "from gensim.models import Word2Vec\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "v2wzWdInbCr6"
      },
      "outputs": [],
      "source": [
        "# ============================================\n",
        "# Pretrained Word Vectors (Task C)\n",
        "# ============================================\n",
        "\n",
        "def recommend_vectors(df: pd.DataFrame, attributes: list, alpha=0.7, top_n=23):\n",
        "    \"\"\"\n",
        "    spaCy pretrained vectors + cosine similarity + sentiment\n",
        "    \"\"\"\n",
        "    try:\n",
        "        nlp = spacy.load(\"en_core_web_md\")\n",
        "    except:\n",
        "        raise RuntimeError(\"Please install en_core_web_md: python -m spacy download en_core_web_md\")\n",
        "\n",
        "    prod = df.groupby(\"product_name\").agg({\n",
        "        \"product_review\": \" \".join,\n",
        "        \"sentiment_raw\": \"mean\"\n",
        "    }).reset_index()\n",
        "\n",
        "    # Build query doc\n",
        "    query_terms = \" \".join([t for a in attributes for t in ATTRIBUTE_SYNONYMS.get(a, [a])])\n",
        "\n",
        "    def doc_vector(text):\n",
        "        doc = nlp(text)\n",
        "        vecs = [t.vector for t in doc if t.has_vector and not t.is_stop]\n",
        "        return np.mean(vecs, axis=0) if vecs else np.zeros(nlp.vocab.vectors_length)\n",
        "\n",
        "    prod_vecs = np.vstack([doc_vector(t) for t in prod[\"product_review\"]])\n",
        "    query_vec = doc_vector(query_terms).reshape(1, -1)\n",
        "\n",
        "    # Cosine similarity\n",
        "    cos_sims = cosine_similarity(prod_vecs, query_vec).flatten()\n",
        "    cos_norm = MinMaxScaler().fit_transform(cos_sims.reshape(-1, 1)).ravel()\n",
        "    sent_norm = MinMaxScaler().fit_transform(prod[[\"sentiment_raw\"]]).ravel()\n",
        "\n",
        "    final_score = alpha * cos_norm + (1 - alpha) * sent_norm\n",
        "\n",
        "    recs = prod.copy()\n",
        "    recs[\"cosine_sim\"] = cos_sims\n",
        "    recs[\"final_score\"] = final_score\n",
        "    return recs.sort_values(\"final_score\", ascending=False).head(top_n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9c394CTbCr6"
      },
      "source": [
        "## Task D: Training Custom Word2Vec Embeddings\n",
        "\n",
        "In this step, instead of relying on pretrained vectors, we train our own Word2Vec model directly on the beer reviews.\n",
        "\n",
        "1. Each word in the reviews is represented as a vector, but the embeddings are now tailored to the beer domain rather than general English.\n",
        "\n",
        "2. We build product-level vectors by averaging the embeddings of words from their reviews.\n",
        "\n",
        "3. Then we compare these product vectors with the attribute vectors using cosine similarity, and again combine that with sentiment scores.\n",
        "\n",
        "4. This approach lets us capture domain-specific nuances (e.g., words like “hoppy”, “malty”, “crisp” may get richer meaning) which general-purpose vectors might miss."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Unq6LAlRbCr6"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Ag6r_GTjbCr6"
      },
      "outputs": [],
      "source": [
        "# ============================================\n",
        "# Step 5: Custom Word2Vec (Task D)\n",
        "# ============================================\n",
        "\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "def train_custom_embeddings(tokenized_reviews, vector_size=100, window=5, min_count=5):\n",
        "    \"\"\"\n",
        "    Train custom Word2Vec embeddings on beer reviews.\n",
        "    \"\"\"\n",
        "    model = Word2Vec(sentences=tokenized_reviews,\n",
        "                     vector_size=vector_size,\n",
        "                     window=window,\n",
        "                     min_count=min_count,\n",
        "                     workers=4)\n",
        "    return model\n",
        "\n",
        "\n",
        "def recommend_custom(df: pd.DataFrame, attributes: list, model: Word2Vec, alpha=0.7, top_n=23):\n",
        "    \"\"\"\n",
        "    Custom Word2Vec + cosine similarity + sentiment\n",
        "    \"\"\"\n",
        "    # Attribute vector\n",
        "    query_vecs = [model.wv[w] for w in attributes if w in model.wv]\n",
        "    if not query_vecs:\n",
        "        print(\"⚠️ No attribute words found in custom vocab.\")\n",
        "        return pd.DataFrame()\n",
        "    query_vector = np.mean(query_vecs, axis=0)\n",
        "\n",
        "    # Product vectors\n",
        "    product_vectors = {}\n",
        "    for name, group in df.groupby(\"product_name\"):\n",
        "        review_vecs = []\n",
        "        for tokens in group[\"tokens\"]:\n",
        "            word_vecs = [model.wv[w] for w in tokens if w in model.wv]\n",
        "            if word_vecs:\n",
        "                review_vecs.append(np.mean(word_vecs, axis=0))\n",
        "        if review_vecs:\n",
        "            product_vectors[name] = np.mean(review_vecs, axis=0)\n",
        "\n",
        "    # Cosine similarity\n",
        "    similarities = {}\n",
        "    for name, vec in product_vectors.items():\n",
        "        sim = np.dot(vec, query_vector) / (np.linalg.norm(vec) * np.linalg.norm(query_vector))\n",
        "        similarities[name] = sim\n",
        "\n",
        "    recs = pd.DataFrame(similarities.items(), columns=[\"product_name\", \"cosine_sim\"])\n",
        "\n",
        "    # Sentiment\n",
        "    sentiments = df.groupby(\"product_name\")[\"sentiment_raw\"].mean().reset_index()\n",
        "    recs = recs.merge(sentiments, on=\"product_name\", how=\"left\")\n",
        "\n",
        "    # Normalize + final score\n",
        "    recs[\"cos_norm\"] = MinMaxScaler().fit_transform(recs[[\"cosine_sim\"]])\n",
        "    recs[\"sent_norm\"] = MinMaxScaler().fit_transform(recs[[\"sentiment_raw\"]])\n",
        "    recs[\"final_score\"] = alpha * recs[\"cos_norm\"] + (1 - alpha) * recs[\"sent_norm\"]\n",
        "\n",
        "    return recs.sort_values(\"final_score\", ascending=False).head(top_n)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        },
        "id": "WtYHxtQMbCr6",
        "outputId": "6a032939-7c26-40ad-b789-43476377daf9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Loaded 10000 reviews after cleaning and sentiment computation.\n",
            "\n",
            "=== Task B: Bag-of-Words Recommendations ===\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-3976ff55-e966-4584-ae48-f08394dc46b4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>product_name</th>\n",
              "      <th>clean_review</th>\n",
              "      <th>sentiment_raw</th>\n",
              "      <th>cosine_sim</th>\n",
              "      <th>final_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>166</th>\n",
              "      <td>Permanent Funeral</td>\n",
              "      <td>drunkin fruits and dripping resinous hops fuck...</td>\n",
              "      <td>0.701922</td>\n",
              "      <td>0.321052</td>\n",
              "      <td>0.892267</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>CBS (Canadian Breakfast Stout)</td>\n",
              "      <td>copenhagen 30 4 2020 35 5 cl bottle from meny ...</td>\n",
              "      <td>0.754722</td>\n",
              "      <td>0.307244</td>\n",
              "      <td>0.892241</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>Canuckley</td>\n",
              "      <td>pours a dense dark black with short lived dark...</td>\n",
              "      <td>0.719647</td>\n",
              "      <td>0.303511</td>\n",
              "      <td>0.863611</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "      \n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3976ff55-e966-4584-ae48-f08394dc46b4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "      \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3976ff55-e966-4584-ae48-f08394dc46b4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3976ff55-e966-4584-ae48-f08394dc46b4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "  \n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                       product_name  \\\n",
              "166               Permanent Funeral   \n",
              "45   CBS (Canadian Breakfast Stout)   \n",
              "47                        Canuckley   \n",
              "\n",
              "                                          clean_review  sentiment_raw  \\\n",
              "166  drunkin fruits and dripping resinous hops fuck...       0.701922   \n",
              "45   copenhagen 30 4 2020 35 5 cl bottle from meny ...       0.754722   \n",
              "47   pours a dense dark black with short lived dark...       0.719647   \n",
              "\n",
              "     cosine_sim  final_score  \n",
              "166    0.321052     0.892267  \n",
              "45     0.307244     0.892241  \n",
              "47     0.303511     0.863611  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Task C: Pretrained Word Vectors (spaCy) ===\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-925c55ee-5a4e-4aaf-9c39-42751a2cefc6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>product_name</th>\n",
              "      <th>product_review</th>\n",
              "      <th>sentiment_raw</th>\n",
              "      <th>cosine_sim</th>\n",
              "      <th>final_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>150</th>\n",
              "      <td>Moment Of Clarity</td>\n",
              "      <td>Black coal with a nice tan thick creamy head. ...</td>\n",
              "      <td>0.808061</td>\n",
              "      <td>0.797539</td>\n",
              "      <td>0.953826</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>BVC</td>\n",
              "      <td>Blend 2 at Side Project Cellar 3/12/25.  I did...</td>\n",
              "      <td>0.887675</td>\n",
              "      <td>0.786592</td>\n",
              "      <td>0.943723</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>All That Is And All That Ever Will Be</td>\n",
              "      <td>Pours a dark brown, but appears black in the g...</td>\n",
              "      <td>0.743565</td>\n",
              "      <td>0.793231</td>\n",
              "      <td>0.894274</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "      \n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-925c55ee-5a4e-4aaf-9c39-42751a2cefc6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "      \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-925c55ee-5a4e-4aaf-9c39-42751a2cefc6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-925c55ee-5a4e-4aaf-9c39-42751a2cefc6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "  \n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                              product_name  \\\n",
              "150                      Moment Of Clarity   \n",
              "25                                     BVC   \n",
              "14   All That Is And All That Ever Will Be   \n",
              "\n",
              "                                        product_review  sentiment_raw  \\\n",
              "150  Black coal with a nice tan thick creamy head. ...       0.808061   \n",
              "25   Blend 2 at Side Project Cellar 3/12/25.  I did...       0.887675   \n",
              "14   Pours a dark brown, but appears black in the g...       0.743565   \n",
              "\n",
              "     cosine_sim  final_score  \n",
              "150    0.797539     0.953826  \n",
              "25     0.786592     0.943723  \n",
              "14     0.793231     0.894274  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Task D: Custom Word2Vec Embeddings ===\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-4dddd3ab-ac56-4d55-a5da-368764019d1c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>product_name</th>\n",
              "      <th>cosine_sim</th>\n",
              "      <th>sentiment_raw</th>\n",
              "      <th>cos_norm</th>\n",
              "      <th>sent_norm</th>\n",
              "      <th>final_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>166</th>\n",
              "      <td>Permanent Funeral</td>\n",
              "      <td>0.738280</td>\n",
              "      <td>0.701922</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.640888</td>\n",
              "      <td>0.892267</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73</th>\n",
              "      <td>Double Dry Hopped Double Mosaic Daydream</td>\n",
              "      <td>0.727004</td>\n",
              "      <td>0.722202</td>\n",
              "      <td>0.975784</td>\n",
              "      <td>0.680097</td>\n",
              "      <td>0.887078</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>121</th>\n",
              "      <td>Jjjuliusss</td>\n",
              "      <td>0.684755</td>\n",
              "      <td>0.774121</td>\n",
              "      <td>0.885057</td>\n",
              "      <td>0.780470</td>\n",
              "      <td>0.853681</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "      \n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4dddd3ab-ac56-4d55-a5da-368764019d1c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "      \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4dddd3ab-ac56-4d55-a5da-368764019d1c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4dddd3ab-ac56-4d55-a5da-368764019d1c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "  \n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                 product_name  cosine_sim  sentiment_raw  \\\n",
              "166                         Permanent Funeral    0.738280       0.701922   \n",
              "73   Double Dry Hopped Double Mosaic Daydream    0.727004       0.722202   \n",
              "121                                Jjjuliusss    0.684755       0.774121   \n",
              "\n",
              "     cos_norm  sent_norm  final_score  \n",
              "166  1.000000   0.640888     0.892267  \n",
              "73   0.975784   0.680097     0.887078  \n",
              "121  0.885057   0.780470     0.853681  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# ----------------------------\n",
        "# Execute all 3 methods\n",
        "# ----------------------------\n",
        "import nltk\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('vader_lexicon')\n",
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_md\")\n",
        "# pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    df = load_and_prepare(\"/content/beer_reviews.csv\")\n",
        "\n",
        "    # --- Task B ---\n",
        "    print(\"\\n=== Task B: Bag-of-Words Recommendations ===\")\n",
        "    bow_recs = recommend_bow(df, USER_ATTRIBUTES).head(3)\n",
        "    display(bow_recs)   # Shows as table in Colab\n",
        "\n",
        "    # --- Task C ---\n",
        "    print(\"\\n=== Task C: Pretrained Word Vectors (spaCy) ===\")\n",
        "    vec_recs = recommend_vectors(df, USER_ATTRIBUTES).head(3)\n",
        "    display(vec_recs)\n",
        "\n",
        "    # --- Task D ---\n",
        "    print(\"\\n=== Task D: Custom Word2Vec Embeddings ===\")\n",
        "    custom_model = train_custom_embeddings(df[\"tokens\"].tolist())\n",
        "    custom_recs = recommend_custom(df, USER_ATTRIBUTES, custom_model).head(3)\n",
        "    display(custom_recs)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sfUu08UdbCr6"
      },
      "source": [
        "# Tfidf vs. SpaCy\n",
        "\n",
        "The two recommendation methods were applied to a collection of user beer reviews, yielding the following top 3 results based on their respective scoring metrics.\n",
        "\n",
        "## Top 3 Beer Recommendations by Method\n",
        "\n",
        "| Method | Rank 1 Beer | Rank 2 Beer | Rank 3 Beer | Primary Style |\n",
        "| :--- | :--- | :--- | :--- | :--- |\n",
        "| **Tfidf (Bag of Words)** | Permanent Funeral | CBS (Canadian Breakfast Stout) | Canuckley | Mixed (Imperial IPA & Stouts) |\n",
        "| **SpaCy (Semantic)** | Moment Of Clarity | BVC | All That Is And All That Ever Will Be | Adjunct Stouts |\n",
        "\n",
        "---\n",
        "\n",
        "## Which Method Gives Better Recommendations?\n",
        "\n",
        "The **SpaCy** method appears to provide **better and more coherent recommendations** in this specific context.\n",
        "\n",
        "### Reasoning\n",
        "\n",
        "1.  **Semantic Coherence (SpaCy)**:\n",
        "    * SpaCy's top recommendations (**Moment Of Clarity**, **BVC**, and **All That Is And All That Ever Will Be**) are all high-rated, **dessert-style Imperial Stouts/Milk Stouts** that prominently feature adjuncts like **chocolate, coffee, maple syrup, and vanilla**.\n",
        "    * This suggests that the model effectively used **semantic processing** to understand the specific flavor profile being described (i.e., sweet, adjunct-heavy, pastry stout characteristics) and matched it to a highly similar group of beers.\n",
        "\n",
        "2.  **Keyword Focus (Tfidf)**:\n",
        "    * The Tfidf model's list is inconsistent, mixing the **Imperial IPA Permanent Funeral** with the **Imperial Stouts CBS and Canuckley**.\n",
        "    * **Tfidf** relies on the frequency and distinctiveness of individual words (term frequency-inverse document frequency). It likely scored both beer styles highly based on **generic positive descriptors** (e.g., \"great,\" \"smooth,\" \"complex,\" \"winner\") rather than the unique flavor terms.\n",
        "    * A simple count of terms like \"pine,\" \"citrus,\" and \"bitter\" (IPA) would be less semantically related to \"chocolate,\" \"maple,\" and \"bourbon\" (Stouts), indicating that Tfidf failed to capture the distinct *meaning* of the reviews and group by flavor profile.\n",
        "\n",
        "For recommending a product like beer, where the **flavor profile and style are critical**, a model with **semantic understanding (SpaCy)** is more valuable than a basic **word-frequency model (Tfidf)**, as it correctly groups products with similar taste and style characteristics."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rp2cZJqAbCr7"
      },
      "source": [
        "## Task E: Comparing with Top-Rated Products  \n",
        "\n",
        "In this task, we ask: *What if we ignore similarity and sentiment scores, and simply choose the 3 highest-rated products from the dataset?*  \n",
        "\n",
        "Key questions to consider:  \n",
        "- Would these products actually meet the needs of a user looking for personalized recommendations?  \n",
        "- Why or why not?  \n",
        "- Let’s analyze and justify whether relying on raw ratings alone is a good strategy.  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ueunR5GbbCr7",
        "outputId": "407e6542-6284-4ffa-a3f3-d9e87e038fec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "product_name\n",
            "Kentucky Brunch Brand Stout       25\n",
            "Trappist Westvleteren 12 (XII)    24\n",
            "Heady Topper                      16\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Step 1: Find max rating\n",
        "max_rating = df['user_rating'].max()\n",
        "\n",
        "# Step 2: Filter beers with max rating\n",
        "top_rated = df[df['user_rating'] == max_rating]\n",
        "\n",
        "# Step 3: Count frequency\n",
        "beer_freq = top_rated['product_name'].value_counts()\n",
        "\n",
        "# Step 4: Pick top 3\n",
        "top_3_beers = beer_freq.head(3)\n",
        "print(top_3_beers)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QTfKrDb_bCr7"
      },
      "source": [
        "# Beer Recommendation Analysis\n",
        "\n",
        "## Ignoring Similarity and Sentiment\n",
        "\n",
        "If we ignore similarity and sentiment, and **only use ratings**, the top-3 beers are:\n",
        "\n",
        "| Rank | Beer                          | Rating | Reviews |\n",
        "|------|-------------------------------|--------|---------|\n",
        "| 1    | Kentucky Brunch Brand Stout   | 5.0    | 25      |\n",
        "| 2    | Trappist Westvleteren 12 (XII)| 5.0    | 24      |\n",
        "| 3    | Heady Topper                  | 5.0    | 16      |\n",
        "\n",
        "These come from the **global highest-rated set**, regardless of the user's requested attributes.\n",
        "\n",
        "---\n",
        "\n",
        "## User Attributes Chosen\n",
        "- **Sweet**\n",
        "- **Smooth**\n",
        "- **Hoppy**\n",
        "\n",
        "---\n",
        "\n",
        "## Attribute-Aware Models (Tasks B–D)\n",
        "\n",
        "When using **BoW (Task B)**, **Pretrained Vectors (Task C)**, and **Custom Embeddings (Task D)**, the following beers consistently appeared at the top:\n",
        "\n",
        "- Permanent Funeral  \n",
        "- Pliny the Elder  \n",
        "- Triple Sunshine  \n",
        "- Abrasive Ale  \n",
        "- Double Dry Hopped Mosaic Daydream  \n",
        "\n",
        "These beers are described in reviews with strong **hoppy, citrus, bitter, or smooth** flavor notes — i.e., directly relevant to the user's preferences.\n",
        "\n",
        "---\n",
        "\n",
        "## Why Ratings Alone Fail\n",
        "\n",
        "- **Kentucky Brunch Brand Stout** and **Trappist Westvleteren 12** are world-class imperial stouts.  \n",
        "  - Reviews emphasize *richness, hype, and exclusivity*.  \n",
        "  - They are highly rated but **not hoppy or citrusy**.  \n",
        "- **Heady Topper** is different: as a Double IPA, it **does align** with *hoppy* and sometimes *smooth*.  \n",
        "- Therefore, a **rating-only approach risks recommending beers that are excellent overall but irrelevant** to the chosen attributes.\n",
        "\n",
        "---\n",
        "\n",
        "## Role of Attribute + Sentiment Scoring\n",
        "\n",
        "- Ratings capture **aggregate popularity**, not **personalized flavor alignment**.  \n",
        "- Attribute + sentiment scoring ensures:  \n",
        "  1. Beers are **similar to requested attributes** (hoppy, smooth, citrus).  \n",
        "  2. Beers are **positively received in reviews**.  \n",
        "- This prevents recommending beers that are “top-rated” but **off-profile**.\n",
        "\n",
        "---\n",
        "\n",
        "If we ignored similarity and sentiment and **only chose the three highest-rated beers**, we would recommend:\n",
        "\n",
        "1. Kentucky Brunch Brand Stout  \n",
        "2. Trappist Westvleteren 12 (XII)  \n",
        "3. Heady Topper  \n",
        "\n",
        "- These are **highly acclaimed**.  \n",
        "- But **only Heady Topper** aligns with *hoppy, smooth*.  \n",
        "- The two stouts do not match the flavor profile and would likely disappoint the user.  \n",
        "\n",
        "**Conclusion:**  \n",
        "Relying on ratings alone is insufficient — popularity ≠ attribute relevance.  \n",
        "Our similarity + sentiment models (Tasks B–D) produced recommendations that consistently emphasize **hoppiness, citrus, and smoothness**, making them **better tailored** to the user's needs.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IP7FCfp4bCr7"
      },
      "source": [
        "##  Task F: Selecting 10 Beers and Finding the Closest Match"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CfCGmuuxbCr7",
        "outputId": "8696d64d-441c-449d-a10a-02222f2dcb79"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Target beer: Blåbær Lambik\n",
            "Most similar competitor: Westly\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import spacy\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# ---------------------------\n",
        "# Step 2. Pick 10 beers\n",
        "# ---------------------------\n",
        "sampled_beers = df['product_name'].drop_duplicates().sample(10)\n",
        "subset_df = df[df['product_name'].isin(sampled_beers)]\n",
        "\n",
        "# ---------------------------\n",
        "# Step 3. Concatenate reviews per beer\n",
        "# ---------------------------\n",
        "beer_docs = subset_df.groupby('product_name')['product_review'].apply(\n",
        "    lambda x: \" \".join(str(r) for r in x)\n",
        ").reset_index()\n",
        "\n",
        "# ---------------------------\n",
        "# Step 4. Load spaCy embeddings\n",
        "# ---------------------------\n",
        "nlp = spacy.load(\"en_core_web_md\")\n",
        "\n",
        "def get_embedding(text):\n",
        "    doc = nlp(text)\n",
        "    # Average word vectors (ignore stopwords & out-of-vocab tokens)\n",
        "    vectors = [token.vector for token in doc if token.has_vector and not token.is_stop]\n",
        "    if len(vectors) > 0:\n",
        "        return np.mean(vectors, axis=0)\n",
        "    else:\n",
        "        return np.zeros(nlp.vocab.vectors_length)\n",
        "\n",
        "beer_docs['embedding'] = beer_docs['product_review'].apply(get_embedding)\n",
        "\n",
        "# Convert to matrix\n",
        "embedding_matrix = np.vstack(beer_docs['embedding'].values)\n",
        "\n",
        "# ---------------------------\n",
        "# Step 5. Cosine similarity\n",
        "# ---------------------------\n",
        "similarity_matrix = cosine_similarity(embedding_matrix)\n",
        "\n",
        "# ---------------------------\n",
        "# Step 6. Pick a target beer and find competitor\n",
        "# ---------------------------\n",
        "target_beer = beer_docs['product_name'].iloc[0]   # first beer in list\n",
        "target_idx = 0\n",
        "\n",
        "# Get similarity scores (exclude self)\n",
        "similarities = similarity_matrix[target_idx]\n",
        "similarities[target_idx] = -1  # so we don't pick itself\n",
        "\n",
        "# Most similar beer\n",
        "competitor_idx = np.argmax(similarities)\n",
        "competitor_beer = beer_docs['product_name'].iloc[competitor_idx]\n",
        "\n",
        "print(f\"Target beer: {target_beer}\")\n",
        "print(f\"Most similar competitor: {competitor_beer}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJaPKRFxbCr7"
      },
      "source": [
        "## Methodology\n",
        "\n",
        "### 1. Selection of Beers  \n",
        "- Ten distinct beers were randomly sampled from the dataset.  \n",
        "- This ensures diversity across styles and brands, minimizing bias in the analysis.  \n",
        "\n",
        "\n",
        "### 2. Aggregation of Reviews  \n",
        "- For each beer, all individual reviews were **concatenated into a single document**.  \n",
        "- This creates a comprehensive representation of customer sentiment and descriptive language.  \n",
        "- Instead of analyzing reviews separately, the **collective voice of consumers** is treated as one profile per beer.  \n",
        "\n",
        "\n",
        "### 3. Text Representation through Embeddings  \n",
        "- Reviews were converted into numerical form using **spaCy’s `en_core_web_md` model**, which provides pretrained **300-dimensional word embeddings**.  \n",
        "- For each beer:  \n",
        "  - Stopwords and words without embeddings were excluded.  \n",
        "  - Vectors for the remaining tokens were **averaged**, producing a single vector.  \n",
        "- The result is a semantic vector capturing the **essence of how consumers describe the beer**.  \n",
        "\n",
        "\n",
        "### 4. Measuring Similarity  \n",
        "- To compare beers, **cosine similarity** was applied between their vectors.  \n",
        "- A higher cosine similarity score means that consumer language describing two beers is more alike.  \n",
        "- This indicates that the beers are **perceived as closer substitutes**.  \n",
        "\n",
        "\n",
        "### 5. Identifying the Closest Competitor  \n",
        "- For the **chosen target beer**, similarity scores were calculated against the other nine beers.  \n",
        "- The beer with the **highest similarity score** (excluding the target itself) was identified as the **closest competitor**.  \n",
        "\n",
        "\n",
        "## Logic Behind the Approach\n",
        "- This method emphasizes **customer perception** rather than objective product attributes (e.g., ABV, style, brewery).  \n",
        "- Consumers describe beers based on **taste, mouthfeel, bitterness, sweetness, aroma**, etc.  \n",
        "- By embedding this descriptive language, hidden relationships between beers can be revealed.  \n",
        "- Two beers may emerge as competitors even if they come from **different breweries or styles**, as long as consumers perceive them similarly.  \n",
        "\n",
        "\n",
        "## Conclusion\n",
        "By averaging **word embeddings** from reviews and applying **cosine similarity**, we identified the closest competitor to the target beer among a sample of ten.  \n",
        "This demonstrates how **NLP can uncover consumer-driven insights** in markets where traditional categories may fail to capture true competitive dynamics.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zHqr5pYGbCr7"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python (beerrec)",
      "language": "python",
      "name": "beerrec"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
